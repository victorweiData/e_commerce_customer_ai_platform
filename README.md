E-Commerce Customer AI Platform

End-to-end MLOps demo built on the public Olist Brazilian E-commerce dataset. It walks through the whole lifecycleâ€”from raw data ingestion to model serving & monitoringâ€”using production-style tooling.

â¸»

ğŸ“ Repository layout

â”œâ”€â”€ customer_ai/            â† Python package (config, features, models)
â”‚   â”œâ”€â”€ data/               â† Feature helpers & dataset joins
â”‚   â””â”€â”€ modeling/           â† `train.py` / `predict.py`
â”œâ”€â”€ data/                   â† raw / interim / processed parquet
â”œâ”€â”€ flows/                  â† Prefect flows (ingest, clean, train, monitor)
â”œâ”€â”€ infra/                  â† docker-compose stack (Postgres, Prefect, MLflow, Grafana)
â”œâ”€â”€ docs/                   â† MkDocs site (optional)
â”œâ”€â”€ tests/                  â† pytest unit tests
â”œâ”€â”€ environment.yml         â† Conda environment spec
â”œâ”€â”€ Makefile                â† one-liners: lint, test, ingest, db-load â€¦
â””â”€â”€ .github/workflows/ci.ymlâ† pre-commit & pytest


â¸»

ğŸš€ Quick-start (local)

# 1ï¸âƒ£  Clone & create environment
conda env create -f environment.yml -n e_comm_ai
conda activate e_comm_ai

# 2ï¸âƒ£  Bring up infra stack (detached)
docker compose -f infra/docker-compose.yml up -d

# 3ï¸âƒ£  Download + unzip raw Olist data
python -m flows.ingest_olist          # or: make ingest-fast

# 4ï¸âƒ£  Clean raw â†’ processed parquet
make clean-data                       # runs Prefect `flows.clean_olist`

# 5ï¸âƒ£  Load processed parquet â†’ Postgres warehouse
make db-load                          # runs Prefect `flows.load_cleaned_to_db`

# 6ï¸âƒ£  Train baseline models & record to MLflow
python -m flows.train_models          # WIP

# 7ï¸âƒ£  Lint, type-check, test
make format lint test

Service	URL	Default creds
MLflow Tracking	http://localhost:5000	â€“
Prefect Orion UI	http://localhost:4200	â€“
Grafana	http://localhost:3000	admin / admin
Postgres	localhost:5432/olist	see .env


â¸»

ğŸ”‘ Environment variables (.env)

Create a simple text file named .env in the project root (sibling to Makefile). This file is ignored by Git, so your credentials stay local.

PG_HOST=localhost
PG_PORT=5432
PG_USER=olist
PG_PASSWORD=olist
PG_DB=olist

These variables are automatically picked up by Prefect flows, Docker Compose, and your notebooks.

â¸»

ğŸ”„ CI/CD
	â€¢	GitHub Actions (ci.yml) installs the Conda environment, then runs pre-commit (black + ruff + mypy) and pytest on every push/PR to main.
	â€¢	Future: add a deployment job that triggers a Prefect deployment or pushes a Docker image to a registry.

â¸»

ğŸ“Š Business objectives & baseline models

#	Objective	Model family	Performance gate
1	Late-delivery prediction	LightGBM classifier	ROC-AUC â‰¥ 0.80
2	Customer churn risk	XGBoost classifier	ROC-AUC â‰¥ 0.75
3	Customer LTV (CLTV)	BG/NBD + GammaGamma	RÂ² â‰¥ 0.45
4	Customer segmentation	K-Means / HDBSCAN	Silhouette â‰¥ 0.25


â¸»

ğŸ› ï¸ Tech stack
	â€¢	Prefect 2 â€“ orchestration
	â€¢	dbt â€“ SQL transformations & tests
	â€¢	Postgres & DuckDB â€“ warehouse/local analytics
	â€¢	MLflow â€“ experiment tracking & model registry
	â€¢	LightGBM / XGBoost / Lifetimes â€“ modeling libs
	â€¢	FastAPI â€“ realtime serving (roadmap)
	â€¢	Evidently + Grafana â€“ data & model drift dashboards
	â€¢	GitHub Actions â€“ CI gates

â¸»

ğŸŒ References
	â€¢	Olist dataset â€“ https://www.kaggle.com/olistbr/brazilian-ecommerce
	â€¢	Prefect docs â€“ https://docs.prefect.io
	â€¢	dbt docs â€“ https://docs.getdbt.com

â¸»

Questions or ideas? Feel free to open an issue or PR!